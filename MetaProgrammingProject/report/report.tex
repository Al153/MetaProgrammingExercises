\documentclass{report}
\usepackage{amssymb}

\usepackage{amsmath}
\usepackage[a4paper,includeheadfoot,margin=2.54cm]{geometry}
\usepackage{breqn}

\usepackage{array}   % for \newcolumntype macro

\usepackage{verbatim}

\usepackage{tabstackengine}
\setstackEOL{\cr}
\setstackgap{L}{\normalbaselineskip}




\newcommand\N[0]{\mathbb{N}}
\newcommand\Q[0]{\mathbb{Q}}

\newcommand \2[0]{\textbf{2}}
\newcommand \3[0]{\textbf{3}}


\newcommand\biimpl[0]{\Leftrightarrow}
\newcommand\impl[0]{\Rightarrow}
\newcommand\impliedBy[0]{\Leftarrow}
\newcommand \inverse[0]{^{-1}}
\newcommand \compose[0]{ \circ}

\newcommand \op[0]{^{op}}

\newcommand \cat[0]{\textbf{C}}
\newcommand \cset[0]{\textbf{Set}}

\newcommand{\todo}[1]{\textbf{#1}}

\begin{document}
\title{A Modular, Extensible, and Polymorphic Graph Query DSL}
\author{Alexander Taylor}

\maketitle
{\large
\begin{tabular}{p{5cm}p{10cm}}
Name:       & \bf Alexander Taylor      \\
CRSID:      & \bf at736 \\
College:    & \bf St John's College  \\
Module:     & \bf Metaprogramming, L305 \\
Assignment: & \bf 4 \\
Word Count: & \bf \todo{todo}\footnote{Calculated by running \texttt{texCount (http://app.uio.no/ifi/texcount/online.php)}}   \\
                   \\ 
\end{tabular}
}



\abstract
This project is an extension of my Part II project \footnote{Dissertation: https://github.com/Al153/PartIIProject/blob/master/diss/diss.pdf,\\ Code: https://github.com/Al153/PartIIProject/tree/master/src}, the purpose of which was to build a purely functional graph database system. Although the DSL I produced for the project did provide Scala-compile-time type checking, it used an ADT to construct DSL terms and hence was not tagless-final. Further more, the DSL required implementations to return values of a specific monad type, which made it unsuitable for implementations other than immediate interpreters, such as an implementation that compiles queries for later execution. While my Part II project focused on the full stack and optimisations of particular backends, this L305 project focuses on the front end of a graph database system. The project's primary aim is to open up the interface of the DSL to more varied implementations. It replicates the original DSL in a Modular tagless-final fashion, allowing implementors to choose which operations and syntax they support. Furthermore, it provides a high degree of polymorphism, both in the types used to represent queries, the return types of the database, and in the typeclasses used by an implementation to classify which types can be stored in the database. The project also includes combinators to generate "free" implementations of parts of the specification of DSLs. Finally, I present three new back-end implementations: a simple, set based, in memory interpreter, interfacing code to plug in the back-ends for my original part II project to this part III project, and a simple optimising compiler implementation that compiles queries to a bytecode for later execution.


\tableofcontents
\newpage

\chapter{The Original Project}
\section{Introduction}
My original part II project built the full stack of a graph database system. It provided a strongly typed DSL, a type-class based framework for allowing an application developer's types to be used in queries, and several different backends targeting an in-memory datastore, PostgreSQL, and the LMDB memory-mapped datastore. This project acts as a DSL generator of sorts for faster, more consistent generation of  DSLs for graph-query executors.
\subsection{The Query Language}
The original project uses an algebraic-datatype-based query language to specify queries that search for pairs of related objects and individual objects. As defined in my dissertation, the basic query constructors are as follows.
\begin{equation}
    \label{PDefinition}
    \begin{split}
    P  &\rightarrow Rel(R) \mbox{ Find pairs related by the named relation R}\\
    &\mid RevRel(R) \mbox{ Find pairs related by the named relation R in the reverse direction}\\
    &\mid Chain(P, P) \mbox{   Find pairs related by the first subquery followed by the second}\\
    &\mid And(P, P) \mbox{  Find pairs related by both of the sub-queries}\\
    &\mid AndRight(P, S) \mbox{  Find pairs related by P where the right value is a result of S}\\
    &\mid AndLeft(P, S) \mbox{  Find pairs related by P where the left value is a result of S}\\
    &\mid Or(P, P) \mbox{  Find pairs related by either of the sub-queries}\\
    &\mid Distinct(P) \mbox{  Find pairs related by P that are not symmetrical}\\
    &\mid Id_A \mbox{ Identity relation}\\
    &\mid Exactly(\mathit{n}, P) \mbox{  Find pairs related by n repetitions of P}\\
    &\mid Upto(\mathit{n}, P) \mbox{  Find pairs related by up to n repetitions of P}\\
    &\mid FixedPoint(P) \mbox{  Find the transitive closure of P}\\
    \end{split}
    \end{equation} 

    \begin{equation}
        \label{SDefinition}
        \begin{split}
        S & \rightarrow Find(F) \mbox{ Find values that match the findable F}\\
        &\mid From(S, P) \mbox{ Find values that are reachable from results of S via P}\\
        &\mid AndS(S, S) \mbox{ Find values that are results of both subqueries}\\
        &\mid OrS(S, S) \mbox{ Find values that are results of either subquery}
        \end{split}
    \end{equation} 

Full details, including the type system that applies over this query language can be found in \todo{Section of my dissertation}. Once a query is built, it may be executed in one of several ways by the \texttt{\todo{DBExecutor}} of a given implementation. For example, the executor may simply read the queries from the database or perhaps do pathfinding over the graph with the queries.
\section{Flaws in the Project}
There are several flaws in the front end of this project, as necessitated by the time constraints of a part II project, as well as my desire to look at the big picture of the system rather than focusing for too long on the front end.
\subsection{Fixed Query ADT}
The original project constructed a fixed ADT representing each query. ADT was then traversed or otherwise evaluated to interpret the results of the query. In order to get pattern-match-exhaustivity checking, one has to seal a trait in Scala. This means that the ADT backing the DSL is fixed and cannot be directly extended or reduced. A tagless-final DSL is much easier to extend or reduce.

\subsection{Lack of Polymorphism}
the lack of polymorphism in the original DSL puts unnecessary constraints on back-end implementation.
\paragraph{Types Stored in the Database}
The original project uses the \texttt{SchemaObject} type-class to specify which types can be stored in the database. This type-class is fixed, only allowing types that can be represented as tuples of simple primitive types to be stored in the database. Allowing polymorphism over the type-class used to verify types manipulated by the DSL allows for more freedom of implementation. For example, we may choose to store more complex types to the database, such as wide floating point values, or higher order relations.

\paragraph{Fixed Return Types}
The original database interface requires implementations to return instances of the specific \texttt{Operation} monad (a stack of asynchrony, state, error monads). And only allows read operations to return the eager \texttt{Set} type of results. That is, the return type is \texttt{Operation[Error, Set[(A, B)]]}. This specific return type constraint prevents implementors from returning more interesting values, such as compiled code for later use, or lazy alternatives to sets. Furthermore, it locked the implementation into using the same monadic, branching time, update semantics specified by the \texttt{Operation} monad.


\chapter{The New DSL}
This section introduces the new structure of the DSL.

\section{Introduction}
In the use cases of this project, I make reference to several different classes of people.

\begin{itemize}
    \item \textbf{spec writer} - The person, in this case myself, building the modules and combinators used to construct back end implementations.
    \item \textbf{Implementor} - The person using this project to build a graph query DSL.
    \item \textbf{Application Programmer} - The person using a graph query DSL, built by the implementor, to build an application.

\end{itemize}
 
\section{Tagless-Final}
The new DSL is a modular tagless-final based system. There are several traits to implement, each containing a subset of the operations defined above. This allows for implementations to only partially implement the specification or to add new modules.
The DSL is polymorphic in the type constructors \texttt{Pair} and \texttt{Single} which are used to specify queries returning pairs or single objects. This allows more flexibility than the original ADT based interface.

\section{Modularity}
The new DSL framework is built in a modular way. 
Allows more freedom to implementors to pick and choose which functionality they want to provide to the database system. This allows more specific DSLs to be designed to use particular parts of the algebra.
\subsection{Important Classes/Types/Traits}
\paragraph{Query Building}
The tagless-final interface for building queries is separated into several pieces.
\todo{Check names}
\begin{itemize}
    \item \textbf{Simple Pairs} - \texttt{and}, \texttt{or}, \texttt{id}, etc.
    \item \textbf{Singles} - All of the single query combinators.
    \item \textbf{Simple Repetitions} - \texttt{upto}, \texttt{exactly}
    \item \textbf{Fixed Point} - \texttt{fixedpoint}
\end{itemize}

This allows implementors to implement the interfaces in separate parts. It also allows for construction of less expressive DSLs, for example, without the fixed point combinator.

\paragraph{Execution}
The methods for interpreting a query are separated out into separate interfaces for each function, straight interpretation of queries, path-finding using queries, and updates to the database. These are separated as in the case of queries to allow for partial implementation.

\paragraph{Assertion and Test Suite}
I have replicated a small subset of the unit testing suite I used in my part II project. This is implemented as a mix-in trait depending on a full DSL implementation, and a monad typeclass for the return type. It consists of boolean operations for testing the structure of unexecuted queries and the result of testing queries, an assertion operation for checking the results of queries, and a syntax module for more natural expression of tests. This suite can be found in section \todo{Where?}.

\subsection{Dependency Management}\label{depManagement}
This module system allows us to delegate dependency management to the type-system. Each module is designed as a mix-in trait. It can make requirements on the rest of the implementations by requiring mix-ins using self type annotation. Hence, modules without the correct dependency on the implementation will not compile. This gives back-end implementors a set of type-level combinators for building the shape of their back-end. It also makes life easier for application writers, since the available methods are visible at compile-time, or write-time when using an IDE, such as Intellij Idea. If one was build a similar modular system in a Java style, this information would not be visible in the type signature of the database system, and could lead to exceptions being thrown at runtime due to an unimplemented method being called.

The dependency management scheme can also be used by implementors to add their own extension modules.

A simple example of type-level dependency management is the \texttt{query.dsl.components.BatchInserts} trait, which supplies some syntactic sugar for inserting items.

\begin{verbatim}
trait BatchInserts[M[_], ToInsert[_, _], Valid[_]] {
   self: Writes[M, ToInsert, Valid] =>
   final def inserts[A: Valid, B: Valid](xs:  ToInsert[A, B]*): M[Unit] =
        self.insert(xs.seq)
}
\end{verbatim}


The trait requires itself to be mixed in with a Writes implementation, and hence provides some syntax to the class. There are further examples of this in the sections about syntax providers and free optimisations.

\section{Syntax}
To facilitate the use of Neo-4j-like arrow syntax, there are a series of syntax provider modules. A syntax provider is a module providing the implicit conversions to allow the required syntax. Each syntax provider is a mix-in, parameter-polymorphic, trait using self-type annotations \footnote{https://docs.scala-lang.org/tour/self-types.html} to manage dependencies using the type-system as discussed in section \ref{depManagement}. Hence the application programmer need only import the DSL implementation's internal methods to get access to the syntax.

\begin{verbatim}
    val dsl: DSL[Type Params] = ...
    import dsl._

    val result = read(Knows -->--> Owns >> (Has4Wheels))
    // result: M[Se[Person, Car]]
\end{verbatim}

Syntax providers are kept modular in order to facilitate extended or partial implementations of the spec. The providers are required, as opposed to globally scoped objects due to the large number of polymorphic type parameters, which the Scala type-system is unable to infer. \todo{Put this last sentence earlier.}


\section{Polymorphism}
A lot of this flexibility and deferral to the scala type system is made possible by the large amount of polymorphism allowed in the system. Each trait is polymorphic in as many variables as possible in order to generalise the system to the greatest extent.


\begin{verbatim}
    trait DSL[M[_], Se[_], Pair[_, _], Single[_], Find[_], Path[_], ToInsert[_, _], Valid[_]]
    extends Backend[M, Se, Pair, Single, Find, Path, ToInsert, Valid]
      with PairSyntaxProvider[Pair, Single, Valid]
      with SingleSyntaxProvider[Pair, Single, Find, Valid]
      with SymmetricSyntaxProvider[Pair, Single, Valid]
      with SimplePairs[Pair, Single, Valid]
      with SimpleRepetition[Pair, Valid]
      with FixedPoint[Pair, Valid]
      with SingleQueries[Pair, Single, Find, Valid]
      with BatchInserts[M, ToInsert, Valid]
\end{verbatim}
\todo{note: the extremely polymorphic DSL trait is parameterised in as many types as possible.}

\subsection{Query Types}
As with most tagless-final interfaces, the \texttt{Pair[A, B]} and \texttt{Single[A]} type constructors are provided as type parameters.
\subsection{Type Validation}
The \texttt{SchemaObject} type-class used in the original project to store application-programmers' types in the database is replaced by the \texttt{Valid[_]} type-class, allowing implementors to specify their own validity type-classes.
\todo{Have I explained what the validity type class is for?}
\subsection{Return Types}
The project is also polymorphic in the return type container and sequencing type constructors. The container type, \texttt{M} wraps the result of all operations, as it generalises the \texttt{Operation} monad used in the original project. The container type can be required to be a monad by using the \texttt{HasMonad[M]} mix-in. Other implementations may want to use another kind of type, such as \texttt{Rep} as the container type. The sequencing type constructor is the type of results returned by read queries. In the original project, it is implemented using eager \texttt{Set}s. Other implementations may want to use lazy sets instead, especially when dealing with large databases.

\subsection{Managing Polymorphism}
The large number of polymorphic type parameters bloats the type signatures of components and means we have to be careful about type inference. For example, if we provided a globally available implicit class with syntax for generating pair queries, it would need to look something like the following.

\begin{verbatim}
implicit class PairSyntax[P[_, _], S[_], Valid[_], A: Valid, B: Valid](p: P[A, B]){
    def &(q: P[A, B]): P[A, B] = and(p, q)
    def -->>(s: S[B]): P[A, B] = andRight(p, s)
    ...
}
\end{verbatim}

In order to apply this syntax to \texttt{p: P[A, B]}, the Scala type system would need to correctly infer types of \texttt{S}, \texttt{Valid}. This is not possible for the Scala type system, meaning that \texttt{Nothing} types would populate the un-inferred type parameters. Ideally, we want Scala's type system to infer as many type parameters as possible and for application programmers to use as few type annotations as possible. As a result of this, having mixed-in syntax providers which provide the correct type parameters gives us the cleanest application syntax.

\chapter{Back-end implementations}

I've provided several simple implementations for this project to showcase features.
\section{Trivial implementation}
The first implementation is one that trivially uses sets  to store objects in memory. The validity type-class is the "Universe" type class that verifies that there exists a finite universe of objects of the parameter type in memory. This implementation uses simple techniques to generate the DSL in a free manner.

\section{Original Back-End}
A second implementation is one that provides a set of connectors to allow a suitable DB instance to be used as as a L305-Project DSL instance. This is a simple case of deferring functionality to the instance's original methods and correctly filling in types. 

\begin{verbatim}
...
= new DSL[...]
    with RuntimeTestTools[...]
    with HasMonad[Op]
    with AssertionTools[Op]
    with Lifts[...] {
    ...
    override def and[A: SchemaObject, B: SchemaObject](
        p: FindPair[A, B], q: FindPair[A, B]
    ): FindPair[A, B] =
        And(p, q)
    ...
    override def upto[A: SchemaObject](
        p: FindPair[A, A], n: Int
    ): FindPair[A, A] =
        Upto(n, p)
    ...
    override def readPair[A: SchemaObject, B: SchemaObject](
        p: FindPair[A, B]
    ): Operation[Err, Set[(A, B)]] =
        d.executor.findPairs(p)
    ...
        
    override def shortestPath[A: SchemaObject](
        start: A, end: A, p: FindPair[A, A]
    ): Operation[Err, Option[Path[A]]] =
        d.executor.shortestPath(start, end, p)
    ...
}
\end{verbatim}
\todo{Note: example of some some implementation of the part II backend converter}

\section{Byte Code Back-End}

In addition to these directly executing back-ends, I have also built a partial back end implementation for constructing back-ends that compile queries to a simple byte-code for later execution. I then created a simple implementation of this back-end which executes the bytecode in an imperative fashion in memory.

\subsection{Further Parameterisation}
This partial implementation allows parameterisation

\subsection{Compilation Steps}
This implementation first maps tagless final terms to a type-erased AST \todo{Link to code file?}. That is, the object types associated with each AST term are discarded. This allows us to make optimising transformations on the AST more easily. \texttt{Upto} terms are replaced with the equivalent \texttt{Exactly} terms, as seen \todo{where?}. Finally, primitive relations, identity relations, and findables are converted to nodes indicating a call to external procedures provided by the sub-implementation.

The \texttt{Reads} module's methods are implemented by next compiling the AST into a bytecode program. Operations such as joins, unions, and intersections have opcode equivalents, whereas \texttt{Exactly} and \texttt{FixedPoint} operations are implemented using conditional loops. Furthermore, simple loop unrolling is used if the number of repetitions in an \texttt{Exactly} is less than 5. A binary exponentiation algorithm is used to find the fixed point.

The \texttt{Reads} module's methods finally return a \texttt{Rep} type (not the same as in LMS) whose \texttt{run} method runs the packaged interpreter over the bytecode then uses subimplementation-provided methods to read values of the correct type from the result.


\subsection{The Bytecode}
The bytecode consists of set of stack machine instructions and is type-parameterized by a type of \texttt{Labels} for making jumps and \texttt{Procedures} for calculating primitive relations and sets. This allows an implementation to pick types that suit the exact use case. The bytecode consists of the following instructions.

\begin{itemize}
    \item Relation manipulation: \texttt{And}, \texttt{Or}, \texttt{Join}, etc.
    \item An external procedure call: \texttt{Call}
    \item Stack manipulation instructions: \texttt{Swap}, \texttt{Dup}, \texttt{Drop}
    \item Conditional and unconditional branches \texttt{DecrementAndJump}, \texttt{BranchIfNotEqual} \todo{name?}, and \texttt{Jump}.
    \item \todo{Any more?}
\end{itemize}


\subsection{Interpreters}
Subimplementations should provide an interpreter for the bytecode. The partial implementation is parameterised in such a way that implementations may provide a safe, monadic, locked down interpreter or a faster, less safe one.

\subsection{Implementation}
As an example, I have constructed a simple full implementation of the bytecode interpreter back-end. It implements the bytecode interpreter in a simple, imperative, stack machine. This does not use monads to control execution or handle errors and instead simply allows any exceptions to bubble up as in a Java program. The \texttt{Compilable} typeclass maps individual objects to a simple identifier which is processed by the stack machine.

\chapter{Free Implementations and Optimisation}
Since the module system exposes polymorphism over many parts of the implementation of a DSL, we can look for ways to exploit this polymorphism to reduce the burden on DSL implementors.

\section{Implementations}
Some modules of DSL implementations can be defined naturally in terms of other modules. For example, as proven in the original project \todo{Which section?}, one can formulate the \texttt{exactly(n, P)} operation as a collection of \texttt{chain} operations. Furthermore, one can formulate \texttt{upto(n, P)} as \texttt{exactly(n, or(p, Id))}. Hence we can freely implement \texttt{exactly} and \texttt{upto} given an implementation of the \texttt{SimplePairs} module. Free implementations give us combinators for generating default methods of DSLs in a clean manner.

In general, we can construct a free implementation of a trait using mix-ins as follows:

\begin{verbatim}
trait Free[TypeParams] extends ToBeImplemented[Types] {
    self: Dependency1[Types1] with Dependency2[Types2] =>
    // implement the methods of `ToBeImplemented` using 
    // methods of `Dependency1` and `Dependency1`
    def foo[A, B](a: A): B = ...
}
\end{verbatim}

A free implementation can be used by mixing it in with implementations of the required dependencies.

\begin{verbatim}
object MyDSL extends Dependency1[Types1] with Dependency2[Types2] with Free[Types]
\end{verbatim}

As an example, I have created a free implementation of \todo{SimpleRepetitions} depending on \todo{SimplePairs} as explained above. This  implementation uses the exponentiation-by-squaring technique explained in my part II project \todo{which section} and can be found in \todo{which section?}

One downside to overuse of free implementations is that they may not provide well optimised or performant queries for particular back ends. For example, it may be possible to carry out a backend-specific optimisation that is not applicable in the general case.

\section{Optimisation}
There currently exist (and it may be possible to find more) examples of queries which can be optimised across many implementations. For example, \texttt{Distinct} distributes over \texttt{and} and \texttt{chain} distributes over \texttt{or}, and \texttt{and} and \texttt{or} distribute over each other. These identities can be exploited to push "narrowing" operations (which decrease the size of the result, e.g. \texttt{and}) to the leaves of the AST and "widening" operations (which increase the size of the result, e.g. \texttt{or}) to the root of the AST. This means that the majority of query evaluation handles smaller subqueries and hence runs faster.

An additional extension, given more time, might be to construct a combinator, which given a \texttt{PairQueries} implementation, returns a new implementation that can freely apply well typed optimisations to an internal GADT before folding over the GADT to produce a query of the original type. Unfortunately, as it is cumbersome to properly fold functions over the GADT in Scala, due to the type-system, I ended up cancelling this extension to the project.

\chapter{Running The Code and Examples}
Viewing and running this project is perhaps best performed in the Intellij Idea IDE, with SBT installed, as one can inspect the inferred type of a term using \todo{Alt + = }, follow the definition of terms using \todo{ctrl + b}, and go back to previous views using \todo{ctrl + alt + left-arrow/right-arrow}.
As the project has some dependencies on my part II project, SBT will download it from github and hence may take some time to run when the project is first compiled.

Examples can be demonstrated by running the main methods in \texttt{examples.TrivialExamples}, \texttt{examples.BytecodeExamples}, and \texttt{examples.Part2Examples}. Each class gives some example queries and also definitions of the appropriate typeclass.


\chapter{Conclusion}
This project has presented a set of tools and example uses of these tools for constructing graph database domain specific languages. It has done so making heavy use of the Scala type-system to allow flexibility of implementation and to ensure type and dependency-safety.

Given more time, I would like to have explored a construction of a type algebra to allow polymorphic optimisations to be applied, entirely provided using mix-in traits. E.g.

\begin{verbatim}
object MyFastImplementation extends FreeOptimisations(MyImplementation) 
    with DistributeJoinsUnions[...]
    with DistinctElimination[...]
    with JoinIdentity[...]
\end{verbatim}

Further, I would like to have had more time to explore bytecode compilation. I would have liked to provide a tagless-final interface for constructing bytecode programs, in order to allow the code to be compiled to more exotic backends, such as cross-compilation.
    
\end{document}
